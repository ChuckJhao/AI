{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train.py\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Input, LSTM\n",
    "from keras.models import Model\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'feature.csv'\n",
    "drop_column = ['Unnamed: 0']\n",
    "reshape_value = 34\n",
    "'''\n",
    "#  0 ~ 27 : time slot 0 ~ 27\n",
    "# 28 : continuous week\n",
    "# 29 ~ 31 : Platform\n",
    "# 32 ~ 33 : connect type\n",
    "# 34 : watch ratio\n",
    "# 35 : hot drama\n",
    "# 36 : new episode next week\n",
    "'''\n",
    "shape_num = 38 - len(drop_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1943406, 38)\n",
      "(1943406, 37)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_name)\n",
    "print(data.shape)\n",
    "data = data.drop(columns = drop_column)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...   27   28   29   30  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    31   32   33   34   35   36  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "data = data.reshape(-1, reshape_value, shape_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57159, 34, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape  #total user: 57159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_data = []\n",
    "for line in data :\n",
    "    line = np.delete(line, -1, axis=0)\n",
    "    line = np.delete(line, -1, axis=0)\n",
    "    n_data.append(line)\n",
    "\n",
    "n_data = np.array(n_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57159, 32, 37)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('labels.csv')\n",
    "label = label.drop(columns=['1', '2'])\n",
    "label = label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx_train = n_data[:35001, :, :]\\nx_test = n_data[35001: , :, :]\\ny_train = label[:35001, :]\\ny_test = label[35001: , :]\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_, x_test , y_, y_test = train_test_split(n_data, label, test_size=0.3, shuffle=True, random_state=110)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_, y_, test_size=0.3, shuffle=True, random_state=30)\n",
    "'''\n",
    "x_train = n_data[:35001, :, :]\n",
    "x_test = n_data[35001: , :, :]\n",
    "y_train = label[:35001, :]\n",
    "y_test = label[35001: , :]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sequence_input = Input(shape=(32, shape_num))\n",
    "\n",
    "x = LSTM(128, dropout=0.375)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(28, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "876/876 [==============================] - 52s 59ms/step - loss: 0.2383 - acc: 0.0482 - val_loss: 0.2179 - val_acc: 0.0405\n",
      "Epoch 2/100\n",
      "876/876 [==============================] - 48s 55ms/step - loss: 0.2193 - acc: 0.0527 - val_loss: 0.2165 - val_acc: 0.0361\n",
      "Epoch 3/100\n",
      "876/876 [==============================] - 47s 54ms/step - loss: 0.2175 - acc: 0.0574 - val_loss: 0.2129 - val_acc: 0.0624\n",
      "Epoch 4/100\n",
      "876/876 [==============================] - 47s 53ms/step - loss: 0.2158 - acc: 0.0651 - val_loss: 0.2120 - val_acc: 0.0867\n",
      "Epoch 5/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2146 - acc: 0.0708 - val_loss: 0.2102 - val_acc: 0.0420\n",
      "Epoch 6/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.2139 - acc: 0.0671 - val_loss: 0.2102 - val_acc: 0.0950\n",
      "Epoch 7/100\n",
      "876/876 [==============================] - 45s 52ms/step - loss: 0.2129 - acc: 0.0692 - val_loss: 0.2085 - val_acc: 0.0633\n",
      "Epoch 8/100\n",
      "876/876 [==============================] - 45s 52ms/step - loss: 0.2120 - acc: 0.0761 - val_loss: 0.2094 - val_acc: 0.0592\n",
      "Epoch 9/100\n",
      "876/876 [==============================] - 45s 52ms/step - loss: 0.2114 - acc: 0.0798 - val_loss: 0.2086 - val_acc: 0.0866\n",
      "Epoch 10/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2111 - acc: 0.0801 - val_loss: 0.2084 - val_acc: 0.0827\n",
      "Epoch 11/100\n",
      "876/876 [==============================] - 48s 55ms/step - loss: 0.2105 - acc: 0.0844 - val_loss: 0.2081 - val_acc: 0.1299\n",
      "Epoch 12/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2103 - acc: 0.0872 - val_loss: 0.2085 - val_acc: 0.0638\n",
      "Epoch 13/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2098 - acc: 0.0827 - val_loss: 0.2079 - val_acc: 0.0770\n",
      "Epoch 14/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2090 - acc: 0.0924 - val_loss: 0.2081 - val_acc: 0.0604\n",
      "Epoch 15/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2090 - acc: 0.0882 - val_loss: 0.2094 - val_acc: 0.0919\n",
      "Epoch 16/100\n",
      "876/876 [==============================] - 49s 56ms/step - loss: 0.2087 - acc: 0.0875 - val_loss: 0.2091 - val_acc: 0.0683\n",
      "Epoch 17/100\n",
      "876/876 [==============================] - 46s 52ms/step - loss: 0.2081 - acc: 0.0962 - val_loss: 0.2089 - val_acc: 0.0528\n",
      "Epoch 18/100\n",
      "876/876 [==============================] - 45s 52ms/step - loss: 0.2074 - acc: 0.0927 - val_loss: 0.2088 - val_acc: 0.0749\n",
      "Epoch 19/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2070 - acc: 0.1000 - val_loss: 0.2090 - val_acc: 0.0554\n",
      "Epoch 20/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2066 - acc: 0.0893 - val_loss: 0.2088 - val_acc: 0.0802\n",
      "Epoch 21/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2060 - acc: 0.0950 - val_loss: 0.2083 - val_acc: 0.0799\n",
      "Epoch 22/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2052 - acc: 0.0957 - val_loss: 0.2103 - val_acc: 0.1092\n",
      "Epoch 23/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.2048 - acc: 0.0972 - val_loss: 0.2104 - val_acc: 0.0981\n",
      "Epoch 24/100\n",
      "876/876 [==============================] - 45s 52ms/step - loss: 0.2045 - acc: 0.0959 - val_loss: 0.2116 - val_acc: 0.1268\n",
      "Epoch 25/100\n",
      "876/876 [==============================] - 44s 51ms/step - loss: 0.2038 - acc: 0.0977 - val_loss: 0.2113 - val_acc: 0.0865\n",
      "Epoch 26/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2031 - acc: 0.1002 - val_loss: 0.2108 - val_acc: 0.0726\n",
      "Epoch 27/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2029 - acc: 0.1019 - val_loss: 0.2122 - val_acc: 0.0793\n",
      "Epoch 28/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.2023 - acc: 0.0975 - val_loss: 0.2128 - val_acc: 0.1490\n",
      "Epoch 29/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2027 - acc: 0.1006 - val_loss: 0.2121 - val_acc: 0.1385\n",
      "Epoch 30/100\n",
      "876/876 [==============================] - 44s 51ms/step - loss: 0.2012 - acc: 0.1037 - val_loss: 0.2120 - val_acc: 0.1070\n",
      "Epoch 31/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.2004 - acc: 0.1015 - val_loss: 0.2127 - val_acc: 0.0821\n",
      "Epoch 32/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.2008 - acc: 0.1049 - val_loss: 0.2123 - val_acc: 0.0840\n",
      "Epoch 33/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1999 - acc: 0.1031 - val_loss: 0.2141 - val_acc: 0.0766\n",
      "Epoch 34/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1998 - acc: 0.1013 - val_loss: 0.2139 - val_acc: 0.1090\n",
      "Epoch 35/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1994 - acc: 0.1032 - val_loss: 0.2144 - val_acc: 0.0887\n",
      "Epoch 36/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1985 - acc: 0.1032 - val_loss: 0.2147 - val_acc: 0.1339\n",
      "Epoch 37/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1984 - acc: 0.0977 - val_loss: 0.2153 - val_acc: 0.1213\n",
      "Epoch 38/100\n",
      "876/876 [==============================] - 49s 56ms/step - loss: 0.1977 - acc: 0.1097 - val_loss: 0.2144 - val_acc: 0.0838\n",
      "Epoch 39/100\n",
      "876/876 [==============================] - 46s 53ms/step - loss: 0.1975 - acc: 0.1043 - val_loss: 0.2153 - val_acc: 0.0602\n",
      "Epoch 40/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1967 - acc: 0.0984 - val_loss: 0.2153 - val_acc: 0.0732\n",
      "Epoch 41/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1963 - acc: 0.0987 - val_loss: 0.2167 - val_acc: 0.0976\n",
      "Epoch 42/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1963 - acc: 0.0968 - val_loss: 0.2189 - val_acc: 0.0656\n",
      "Epoch 43/100\n",
      "876/876 [==============================] - 44s 51ms/step - loss: 0.1955 - acc: 0.1012 - val_loss: 0.2176 - val_acc: 0.0717\n",
      "Epoch 44/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1946 - acc: 0.1047 - val_loss: 0.2186 - val_acc: 0.1095\n",
      "Epoch 45/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1947 - acc: 0.1005 - val_loss: 0.2192 - val_acc: 0.0799\n",
      "Epoch 46/100\n",
      "876/876 [==============================] - 44s 51ms/step - loss: 0.1944 - acc: 0.0977 - val_loss: 0.2191 - val_acc: 0.1139\n",
      "Epoch 47/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1933 - acc: 0.1034 - val_loss: 0.2183 - val_acc: 0.0782\n",
      "Epoch 48/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1933 - acc: 0.0996 - val_loss: 0.2186 - val_acc: 0.0808\n",
      "Epoch 49/100\n",
      "876/876 [==============================] - 48s 55ms/step - loss: 0.1924 - acc: 0.1058 - val_loss: 0.2191 - val_acc: 0.0887\n",
      "Epoch 50/100\n",
      "876/876 [==============================] - 46s 52ms/step - loss: 0.1920 - acc: 0.1024 - val_loss: 0.2210 - val_acc: 0.0866\n",
      "Epoch 51/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1920 - acc: 0.1005 - val_loss: 0.2205 - val_acc: 0.0927\n",
      "Epoch 52/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1917 - acc: 0.0972 - val_loss: 0.2209 - val_acc: 0.0814\n",
      "Epoch 53/100\n",
      "876/876 [==============================] - 46s 53ms/step - loss: 0.1909 - acc: 0.1011 - val_loss: 0.2216 - val_acc: 0.0850\n",
      "Epoch 54/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1906 - acc: 0.1039 - val_loss: 0.2215 - val_acc: 0.0938\n",
      "Epoch 55/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1899 - acc: 0.1046 - val_loss: 0.2240 - val_acc: 0.0860\n",
      "Epoch 56/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1893 - acc: 0.1006 - val_loss: 0.2229 - val_acc: 0.1163\n",
      "Epoch 57/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1893 - acc: 0.1053 - val_loss: 0.2233 - val_acc: 0.0843\n",
      "Epoch 58/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1890 - acc: 0.1011 - val_loss: 0.2287 - val_acc: 0.0838\n",
      "Epoch 59/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1885 - acc: 0.1039 - val_loss: 0.2245 - val_acc: 0.1025\n",
      "Epoch 60/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1884 - acc: 0.0987 - val_loss: 0.2252 - val_acc: 0.0696\n",
      "Epoch 61/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1880 - acc: 0.0996 - val_loss: 0.2244 - val_acc: 0.0956\n",
      "Epoch 62/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1876 - acc: 0.1015 - val_loss: 0.2259 - val_acc: 0.0790\n",
      "Epoch 63/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1878 - acc: 0.1034 - val_loss: 0.2249 - val_acc: 0.1036\n",
      "Epoch 64/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1869 - acc: 0.1023 - val_loss: 0.2267 - val_acc: 0.0971\n",
      "Epoch 65/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1866 - acc: 0.1030 - val_loss: 0.2265 - val_acc: 0.1106\n",
      "Epoch 66/100\n",
      "876/876 [==============================] - 42s 48ms/step - loss: 0.1862 - acc: 0.1048 - val_loss: 0.2274 - val_acc: 0.0863\n",
      "Epoch 67/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1865 - acc: 0.1067 - val_loss: 0.2273 - val_acc: 0.0646\n",
      "Epoch 68/100\n",
      "876/876 [==============================] - 46s 52ms/step - loss: 0.1855 - acc: 0.0995 - val_loss: 0.2274 - val_acc: 0.1200\n",
      "Epoch 69/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1856 - acc: 0.1036 - val_loss: 0.2275 - val_acc: 0.0871\n",
      "Epoch 70/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1848 - acc: 0.1037 - val_loss: 0.2284 - val_acc: 0.0981\n",
      "Epoch 71/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1841 - acc: 0.1020 - val_loss: 0.2278 - val_acc: 0.0732\n",
      "Epoch 72/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1845 - acc: 0.1058 - val_loss: 0.2296 - val_acc: 0.1080\n",
      "Epoch 73/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1836 - acc: 0.1018 - val_loss: 0.2298 - val_acc: 0.0851\n",
      "Epoch 74/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1840 - acc: 0.1012 - val_loss: 0.2287 - val_acc: 0.0975\n",
      "Epoch 75/100\n",
      "876/876 [==============================] - 46s 53ms/step - loss: 0.1832 - acc: 0.1065 - val_loss: 0.2319 - val_acc: 0.0761\n",
      "Epoch 76/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1833 - acc: 0.1044 - val_loss: 0.2318 - val_acc: 0.1037\n",
      "Epoch 77/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1826 - acc: 0.1032 - val_loss: 0.2298 - val_acc: 0.0974\n",
      "Epoch 78/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1827 - acc: 0.1059 - val_loss: 0.2290 - val_acc: 0.1241\n",
      "Epoch 79/100\n",
      "876/876 [==============================] - 45s 52ms/step - loss: 0.1823 - acc: 0.1045 - val_loss: 0.2317 - val_acc: 0.1005\n",
      "Epoch 80/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1823 - acc: 0.1059 - val_loss: 0.2307 - val_acc: 0.0910\n",
      "Epoch 81/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1822 - acc: 0.1002 - val_loss: 0.2313 - val_acc: 0.0852\n",
      "Epoch 82/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1818 - acc: 0.1032 - val_loss: 0.2327 - val_acc: 0.0756\n",
      "Epoch 83/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1817 - acc: 0.1042 - val_loss: 0.2328 - val_acc: 0.0901\n",
      "Epoch 84/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1810 - acc: 0.1083 - val_loss: 0.2342 - val_acc: 0.0868\n",
      "Epoch 85/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1813 - acc: 0.1040 - val_loss: 0.2337 - val_acc: 0.1023\n",
      "Epoch 86/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1806 - acc: 0.1017 - val_loss: 0.2318 - val_acc: 0.0841\n",
      "Epoch 87/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1807 - acc: 0.1087 - val_loss: 0.2346 - val_acc: 0.0996\n",
      "Epoch 88/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1801 - acc: 0.1122 - val_loss: 0.2325 - val_acc: 0.0832\n",
      "Epoch 89/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1804 - acc: 0.1069 - val_loss: 0.2338 - val_acc: 0.0735\n",
      "Epoch 90/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1794 - acc: 0.1114 - val_loss: 0.2344 - val_acc: 0.0876\n",
      "Epoch 91/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1791 - acc: 0.1044 - val_loss: 0.2351 - val_acc: 0.0818\n",
      "Epoch 92/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1795 - acc: 0.1063 - val_loss: 0.2329 - val_acc: 0.0896\n",
      "Epoch 93/100\n",
      "876/876 [==============================] - 44s 51ms/step - loss: 0.1788 - acc: 0.1059 - val_loss: 0.2342 - val_acc: 0.1275\n",
      "Epoch 94/100\n",
      "876/876 [==============================] - 43s 49ms/step - loss: 0.1786 - acc: 0.1091 - val_loss: 0.2352 - val_acc: 0.0752\n",
      "Epoch 95/100\n",
      "876/876 [==============================] - 49s 56ms/step - loss: 0.1785 - acc: 0.1044 - val_loss: 0.2344 - val_acc: 0.0956\n",
      "Epoch 96/100\n",
      "876/876 [==============================] - 54s 61ms/step - loss: 0.1782 - acc: 0.1101 - val_loss: 0.2359 - val_acc: 0.1015\n",
      "Epoch 97/100\n",
      "876/876 [==============================] - 49s 56ms/step - loss: 0.1779 - acc: 0.1049 - val_loss: 0.2358 - val_acc: 0.0986\n",
      "Epoch 98/100\n",
      "876/876 [==============================] - 44s 50ms/step - loss: 0.1779 - acc: 0.1044 - val_loss: 0.2360 - val_acc: 0.1176\n",
      "Epoch 99/100\n",
      "876/876 [==============================] - 45s 51ms/step - loss: 0.1776 - acc: 0.1052 - val_loss: 0.2353 - val_acc: 0.1033\n",
      "Epoch 100/100\n",
      "876/876 [==============================] - 43s 50ms/step - loss: 0.1779 - acc: 0.1075 - val_loss: 0.2361 - val_acc: 0.0899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b2d701c3a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.asctime( time.localtime(time.time()) )\n",
    "model.fit(x_train, y_train, shuffle=True, epochs=100, batch_size=32, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kktv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('kktv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 37)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               84992     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28)                3612      \n",
      "=================================================================\n",
      "Total params: 105,116\n",
      "Trainable params: 105,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787/1787 [==============================] - 29s 16ms/step - loss: 0.1976 - acc: 0.1049\n",
      "Test loss :  0.19762766361236572\n",
      "Test accuracy :  0.10493535548448563\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(n_data, label)\n",
    "\n",
    "print('Test loss : ', score[0])\n",
    "print('Test accuracy : ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC :  0.9317892317930275\n",
      "Test AUC :  0.8311334881848944\n",
      "Execute from  Thu Oct 29 15:23:38 2020 to Thu Oct 29 16:38:53 2020\n"
     ]
    }
   ],
   "source": [
    "train_predict = model.predict(x_train)\n",
    "test_predict = model.predict(x_test)\n",
    "\n",
    "'''\n",
    "train_predict = train_predict.reshape(-1, 1)\n",
    "test_predict = test_predict.reshape(-1, 1)\n",
    "y_predict = y_predict.reshape(-1,1)\n",
    "label = label.reshape(-1,1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "'''\n",
    "print('Train AUC : ', metrics.roc_auc_score(y_train, train_predict))\n",
    "print('Test AUC : ', metrics.roc_auc_score(y_test, test_predict))\n",
    "\n",
    "\n",
    "\n",
    "print('Execute from ', start_time, 'to', time.asctime( time.localtime(time.time()) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03518334, 0.8494363 , 0.00840411, 0.04767689, 0.02338672,\n",
       "        0.8758188 , 0.00233707, 0.08195284, 0.0264883 , 0.79590094,\n",
       "        0.00411975, 0.02428538, 0.03484058, 0.78319466, 0.00259039,\n",
       "        0.06341517, 0.0484232 , 0.6941031 , 0.02720025, 0.25332913,\n",
       "        0.6262193 , 0.8477131 , 0.22668076, 0.30748177, 0.6669688 ,\n",
       "        0.820618  , 0.00948685, 0.00962505]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y = model.predict(x_train[8:9])\n",
    "predict_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[8:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre=np.where(predict_y>1,1,0)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  5,  9, 13, 19, 20, 21, 23, 24, 25], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pre!=y_train[8:9])[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
